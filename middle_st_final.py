import re
import random
import streamlit as st
from langchain.vectorstores import FAISS
# from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.callbacks import get_openai_callback
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from sklearn.metrics.pairwise import cosine_similarity


st.set_page_config(page_title="ëª¨ì˜ ë©´ì ‘ : AI ë©´ì ‘ê´€", page_icon="âœ’", layout="centered")

# url í›„ë³´ : https://drive.google.com/file/d/1Xjz2eUbpPqXw8qfL6DXIXnptaYuUOu2V/view?usp=sharing
# img í›„ë³´ : https://img.freepik.com/free-vector/job-interview-conversation_74855-7566.jpg?t=st=1733911614~exp=1733915214~hmac=ec13893600536af309286f5744bfd5eb1c690e5274fbe84367b285a02390f8eb&w=1380
# img í›„ë³´ : https://img.freepik.com/premium-vector/user-chat-bot-conversation-chatgpt-tiny-man-sitting-computer-desk-type-text_88272-9822.jpg?w=1380
st.markdown(
         f"""
         <style>
         .stApp {{
             background-image: url("https://img-c.udemycdn.com/course/750x422/5927120_ef97.jpg");
             background-attachment: fixed;
             background-size: cover
             
         }}
         </style>
         """,
         unsafe_allow_html=True
     )
st.markdown(
    """
    <style>
        section[data-testid="stSidebar"] {
            width: 800px !important;
        }
        div[class="st-emotion-cache-4uzi61 e1f1d6gn0"] {
            background-color:#eadba3;
            }
        div[data-testid="stExpander"]{
            background-color:#f4e5ad;
        }
    </style>
    """,
    unsafe_allow_html=True,
)
#stVerticalBlockBorderWrapper

# st.markdown(
#     """
#     <style>
#         div[class="st-emotion-cache-4uzi61 e1f1d6gn0"] {
#             background-color:pink;
#             width:600px;
#         }
#     </style>
#     """,
#     unsafe_allow_html=True,
# )

# API keyë¥¼ ì½ì–´ì˜¤ê¸° ìœ„í•´ env load
from dotenv import load_dotenv
load_dotenv()

llm = ChatOpenAI(model='gpt-4o',temperature=0)
output_parser = StrOutputParser()
embedding_model = OpenAIEmbeddings()

def similarity(a, b):
    return cosine_similarity([a], [b])[0][0]

vectorstore = FAISS.load_local(
    folder_path = 'faiss_db',
    index_name = 'faiss_index',
    embeddings = embedding_model,
    allow_dangerous_deserialization = True
)
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 10})



if "chain" not in st.session_state:
    st.session_state["chain"] = []


################################
# ìœ„ëŠ” DATA LOAD
################################
# ì•„ë˜ëŠ” ì‚¬ìš© ì˜ˆì‹œ - ì €ëŸ° ì‹ìœ¼ë¡œ FAISS cache dataë¥¼ ëŒ€ë‹µê³¼ì •ì— ì§‘ì–´ë„£ìœ¼ë©´ ë  ê²ƒ ê°™ë‹¤
################################


# company_nameê³¼ position_nameì„ submit_buttonì„ í†µí•´ ì…ë ¥ë°›ì•˜ë‹¤ê³  ê°€ì • ì‹œ

prompt_1 = PromptTemplate.from_template(
    """
    ë„ˆëŠ” AI ë©´ì ‘ê´€ì´ì•¼. questionì„ ë¶„ì„í•´ì„œ ì§ˆë¬¸ì˜ Important factorsë¥¼ íŒë‹¨í•´.
    contextì— ìˆëŠ” ì •ë³´ë¥¼, íŒë‹¨í•œ Important factorsë¥¼ ê¸°ë°˜ìœ¼ë¡œ new interview questionsì„ ë§Œë“¤ì–´ ì¶œë ¥í•´ì¤˜.
    ë‹¨, new interview questionsì˜ Import factorsê°€ ë„ˆë¬´ ì¤‘ë³µë˜ë©´ ì•ˆë¼.

    ëŒ€ë‹µì€ ì´ í˜•íƒœì˜ í•œê¸€ë¡œ ì¶œë ¥í•´ì¤˜.
    ### Important factors : \n\n ### new interview questions : 

    # context : {context}
    # question : {question}
    # new interview questions :
    # Important factors :
    """
    )
prompt_2 = PromptTemplate.from_template(
    # ë‘ ë²ˆì§¸ prompt
    """
    # interview_question : {interview_question}
    # Important_factor : {Important_factor}
    # context : {context}

    ë„ˆëŠ” AI ë©´ì ‘ê´€ì´ì•¼. ë©´ì ‘ìì—ê²Œ interview_question í•  ê²ƒì´ê³ , ê·¸ ì˜ë„ëŠ” Important_factorë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•¨ì´ì•¼.
    ë©´ì ‘ìëŠ” ë„ˆì—ê²Œ context ë¼ê³  ëŒ€ë‹µì„ í–ˆì–´.
    ë„ˆëŠ” contextë¥¼ í†µí•´ Important_factorë¥¼ íŒë‹¨í•  ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë‚´ì•¼í•´.
    íŒë‹¨í•  ìˆ˜ ì—†ë‹¤ë©´, 'ì§ˆë¬¸ìì˜ ì˜ë„ë¥¼ í¬í•¨í•˜ì§€ ëª»í•œ ëŒ€ë‹µì…ë‹ˆë‹¤. ì œê°€ ìƒê°í•˜ëŠ” ëª¨ë²”ë‹µì•ˆì„ ì¶œë ¥í•˜ê² ìŠµë‹ˆë‹¤.'ë¼ê³  ì¶”ê°€ë¡œ ì¶œë ¥í•´ì¤˜.
    íŒë‹¨í•  ìˆ˜ ìˆë‹¤ë©´, contextì˜ ë‚´ìš©ì´ ì•„ë˜ì˜ í•­ëª©ë“¤ì„ ë§Œì¡±ì‹œì¼°ëŠ”ê°€ í™•ì¸í•´ì¤˜.
    
    - ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í‘œí˜„ì„ í•´ì•¼í•œë‹¤. 'ì•„ë§ˆë„', 'ëŒ€ì¶©' ê°™ì€ ëª¨í˜¸í•œ í‘œí˜„ì€ ì‚¬ìš©í•˜ë©´ ì•ˆëœë‹¤.
    - êµ¬ì²´ì ì¸ ì‚¬ë¡€ í™œìš©ì„ í•´ì•¼í•œë‹¤.
    - ê¸ì •ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•´ì•¼í•œë‹¤. ì´ì „ ì§ì¥, ë™ë£Œ, ê²½í—˜ì— ëŒ€í•œ ë¶€ì •ì ì¸ ì–¸ê¸‰ì€ í•˜ë©´ ì•ˆëœë‹¤.
    - íšŒì‚¬ì™€ ì§ë¬´ì— ëŒ€í•œ ì¶©ë¶„í•œ ì´í•´ë„ë¥¼ ë³´ì—¬ì¤˜ì•¼í•œë‹¤.

    ë§Œì¡±ì‹œí‚¤ì§€ ëª»í•œ í•­ëª©ì„ ë³´ì™„í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ contextë¥¼ ìˆ˜ì •í•˜ê³  ì¶œë ¥ì‹œì¼œì¤˜.

    ëŒ€ë‹µì€ ì´ í˜•íƒœë¡œ ì¶œë ¥í•´ì¤˜.

    ### interview_question :
    ### Important_factor :
    ### ìˆ˜ì •í•œ ë‹µë³€ :
    """
    )

chain_1 = prompt_1|llm|output_parser
chain_2 = prompt_2|llm|output_parser

st.session_state["chain"].extend([chain_1,chain_2])


#### ë³¸ë¬¸ ####
if "lock" not in st.session_state:
    st.session_state["lock"] = False

if "answer_input" not in st.session_state:
    st.session_state["answer_input"] = ''

if "question_input" not in st.session_state:
    st.session_state["question_input"] = ''

if "output_question" not in st.session_state:
    st.session_state["output_question"]=[]

if "output_factors" not in st.session_state:
    st.session_state["output_factors"]=[]

if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

if "text_history" not in st.session_state:
    st.session_state["text_history"] = []

if "result_qna" not in st.session_state:
    st.session_state["result_qna"] = []

if "call_back" not in st.session_state:
    st.session_state["call_back"] = []

def compiler(x):
    x = re.sub(r'"*\d.\s','',x)
    return x

def chat_actions():
    st.session_state["chat_history"].append(st.session_state.input_text)
    st.session_state["text_history"].append(st.session_state.answer_input)
    st.session_state["lock"] = True


with get_openai_callback() as cb:
    with st.sidebar:

        st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",on_submit=chat_actions,key="input_text",disabled=st.session_state.lock)

        if len(st.session_state.chat_history)==0 :
            st.cache_data.clear()
        else:
            st.sidebar.header(st.session_state.chat_history[0])
            if None in st.session_state.chat_history:
                st.session_state.chat_history.remove(None)
            # if len(st.session_state.chat_history)>1: ì´ˆê¸°í™” ë¶€ë¶„ ìƒê°í•´ë´ì•¼í•¨.
            #     st.write(st.session_state.chat_history)
            #     st.write(st.session_state.text_history)
            #     del st.session_state.chat_history
            #     del st.session_state.text_history
            #     del st.session_state.output_factors
            #     del st.session_state.output_question
            #     del st.session_state.text_history
            #     st.cache_data.clear()
            #     st.rerun()

            @st.cache_data
            def question_list():
                ret = retriever.invoke(st.session_state.chat_history[0])
                result_1 = st.session_state["chain"][0].invoke({'context':st.session_state.chat_history[0],'question':ret})

                result_split = re.split(r'#.*:',result_1)
                result_split = [b for b in result_split if b not in ['',' ']]


                Important_factors = result_split[0].split('\n')
                Important_factors = [b for b in Important_factors if b not in ['',' ']]

                interview_questions = result_split[1].split('\n')
                interview_questions = [b for b in interview_questions if b not in ['',' ']]

                return Important_factors, interview_questions

            Important_factors, interview_questions = question_list()

            interview_questions_del = [i for i in interview_questions if i not in st.session_state["output_question"]]
            Important_factors_del = [i for i in Important_factors if i not in st.session_state["output_factors"]]
            
            try:
                x = random.sample(range(0,len(interview_questions_del)),1)[0]
                output_question = interview_questions_del[x]
                st.session_state["output_question"].append(output_question)

                output_factors = Important_factors_del[x]
                st.session_state["output_factors"].append(output_factors)
                if len(st.session_state["output_question"])>1:
                    pass
                else:
                    st.write(f'### ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. \n {compiler(st.session_state["output_question"][-1])}')

                
                

                if st.text_input('ë©´ì ‘ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.',on_change=chat_actions,key="answer_input") :

                    # ì²´ì¸ í˜•ì„±.
                    result_2 = st.session_state["chain"][1].invoke({'context':st.session_state.text_history[-1],'interview_question':st.session_state["output_question"][-2],'Important_factor':st.session_state["output_factors"][-2]})
                    result_2_split = re.split(r'#.*:',result_2)


                    # ì „ì²˜ë¦¬
                    result_2_split = [c for c in result_2_split if c not in ['',' ']]
                    result_2_split = [c.strip() for c in result_2_split]
                    # ì „ì²˜ë¦¬ í•œ ë’¤, ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ë¹ˆ ìš”ì†Œë¥¼ ì œê±°.
                    
                    new_question = result_2_split[0] # :: new question
                    important_factor = result_2_split[1] # :: important factor

                    if '\n\n' in result_2_split[2]:
                        new_answer = result_2_split[2].split('\n\n')
                        reject_word_2 = new_answer[1]
                        reject_warn = 'ì§ˆë¬¸ìì˜ ì˜ë„ë¥¼ í¬í•¨í•˜ì§€ ëª»í•œ ëŒ€ë‹µì…ë‹ˆë‹¤.\nì œê°€ ìƒê°í•˜ëŠ” ëª¨ë²”ë‹µì•ˆì„ ì¶œë ¥í•˜ê² ìŠµë‹ˆë‹¤.'
                    else:
                        reject_word_2 = result_2_split[2] # :: new answer
                        reject_warn = ''

                    result_qna_1 = compiler(st.session_state["output_question"][-2]) # ë°›ì€ ì§ˆë¬¸
                    result_qna_2 = compiler(st.session_state["output_factors"][-2]) # ë°›ì€ ì§ˆë¬¸ì˜ ì˜ë„
                    result_qna_3 = st.session_state.text_history[-1] # ì‚¬ìš©ìì˜ ëŒ€ë‹µ
                    result_qna_4 = reject_warn # ë‹µì•ˆì˜ ì í•©ì„±
                    result_qna_5 = reject_word_2 # ìˆ˜ì • ë‹µì•ˆ
                    result_qna_5_1 = [result_qna_3,result_qna_5]                
                    result_qna_5_2 = embedding_model.embed_documents(result_qna_5_1)
                    result_qna_6 = similarity(result_qna_5_2[0], result_qna_5_2[-1]) # ìœ ì‚¬ì„±
                    
                    st.session_state["result_qna"].append([result_qna_1,result_qna_2,result_qna_3,result_qna_4,result_qna_5,result_qna_5_1,result_qna_5_2,result_qna_6])

                    if len(interview_questions)>len(st.session_state["output_question"]):
                        st.write('')
                        st.subheader('ë‹¤ìŒ ì§ˆë¬¸ì…ë‹ˆë‹¤.')
                        st.write(compiler(st.session_state["output_question"][-1]))
                        st.write('\n\n\n')
                        st.write('----')
                        container_1 = st.container(border=True)
                        container_1.subheader('ë©´ì ‘ íŒ : AIì˜ prompt ê¸°ë°˜ ğŸ“Œ')
                        st.write('')

                        container_2 = st.container(border=True)
                        container_2.write("- ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í‘œí˜„ì„ í•´ì•¼í•œë‹¤.")
                        container_2.write("ğŸ‘‰ 'ì•„ë§ˆë„', 'ëŒ€ì¶©' ê°™ì€ ëª¨í˜¸í•œ í‘œí˜„ì€ ì‚¬ìš©í•˜ë©´ ì•ˆëœë‹¤.")
                        container_2.write('')
                        container_2.write("- êµ¬ì²´ì ì¸ ì‚¬ë¡€ í™œìš©ì„ í•´ì•¼í•œë‹¤.")
                        container_2.write('')
                        container_2.write("- ê¸ì •ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•´ì•¼í•œë‹¤.")
                        container_2.write("ğŸ‘‰ ì´ì „ ì§ì¥, ë™ë£Œ, ê²½í—˜ì— ëŒ€í•œ ë¶€ì •ì ì¸ ì–¸ê¸‰ì€ í•˜ë©´ ì•ˆëœë‹¤.")
                        container_2.write('')
                        container_2.write("- íšŒì‚¬ì™€ ì§ë¬´ì— ëŒ€í•œ ì¶©ë¶„í•œ ì´í•´ë„ë¥¼ ë³´ì—¬ì¤˜ì•¼í•œë‹¤.")

                        st.write('---')
                        st.write('')
                        expander_cb = st.expander('Check_Token_Cost')
                        expander_cb.write(cb)

                            
                    else:
                        st.write('ì¤€ë¹„ëœ ì§ˆë¬¸ì´ ëª¨ë‘ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.')

            except ValueError :
                st.write('ì¤€ë¹„ëœ ì§ˆë¬¸ì´ ëª¨ë‘ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.')
                st.write('ìƒˆë¡œê³ ì¹¨ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!')


    if len(st.session_state["result_qna"])>0:
        for l in range(0,len(st.session_state["result_qna"])):
            expander = st.expander(st.session_state["result_qna"][l][0]) # ë°›ì€ ì§ˆë¬¸
            expander.write(st.session_state["result_qna"][l][1]) # ë°›ì€ ì§ˆë¬¸ì˜ ì˜ë„
            expander.write('---')
            expander.write(st.session_state["result_qna"][l][2]) # ì‚¬ìš©ìì˜ ëŒ€ë‹µ
            expander.write('')
            expander.write(st.session_state["result_qna"][l][3]) # ë‹µì•ˆì´ ì ì ˆí–ˆëŠ”ì§€
            expander.write('---')
            expander.write(st.session_state["result_qna"][l][4]) # ìˆ˜ì •í•œ ë‹µì•ˆ
            expander.write('')
            expander.write(st.session_state["result_qna"][l][7]) # ìœ ì‚¬ì„±.
            st.write('----')
    else:
        container_1 = st.container(border=True)
        container_1.subheader('ë©´ì ‘ íŒ : AIì˜ prompt ê¸°ë°˜ ğŸ“Œ')
        st.write('')
        container_2 = st.container(border=True)
        container_2.write("- ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í‘œí˜„ì„ í•´ì•¼í•œë‹¤.")
        container_2.write("ğŸ‘‰ 'ì•„ë§ˆë„', 'ëŒ€ì¶©' ê°™ì€ ëª¨í˜¸í•œ í‘œí˜„ì€ ì‚¬ìš©í•˜ë©´ ì•ˆëœë‹¤.")
        container_2.write('')
        container_2.write("- êµ¬ì²´ì ì¸ ì‚¬ë¡€ í™œìš©ì„ í•´ì•¼í•œë‹¤.")
        container_2.write('')
        container_2.write("- ê¸ì •ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•´ì•¼í•œë‹¤.")
        container_2.write("ğŸ‘‰ ì´ì „ ì§ì¥, ë™ë£Œ, ê²½í—˜ì— ëŒ€í•œ ë¶€ì •ì ì¸ ì–¸ê¸‰ì€ í•˜ë©´ ì•ˆëœë‹¤.")
        container_2.write('')
        container_2.write("- íšŒì‚¬ì™€ ì§ë¬´ì— ëŒ€í•œ ì¶©ë¶„í•œ ì´í•´ë„ë¥¼ ë³´ì—¬ì¤˜ì•¼í•œë‹¤.")

        # ë©´ì ‘ íŒ ì¶”ê°€í•˜ê¸°.



